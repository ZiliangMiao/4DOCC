mode: "pretrain"

##Data
data:
  dataset_name: "nuscenes"  # "kitti", "argo"
  dataset_pct: 100  # not used now; percentage of data used for training
  voxel_size: 1.0  # voxel size
  scene_bbox: [-70.0, -70.0, -4.5, 70.0, 70.0, 4.5]  # valid point cloud range
  time_interval: 0.05
  t_scans: 6  # number of input point cloud scan 6, 9, 6 (num of input scans = output scans)
  n_skip: 4
  feat_dim: 256  # feature dimension of explicit feature volume
  n_rays_scan: 128
  n_points_ray: 1024
  filter_outside_bbox: True
#  transform: True # If true, the points are pose-aligned before feeding to the model
  ego_mask: True  # mask the points of ego-vehicle, 4docc pretraining default=True
  shuffle: False  # shuffle the dataset
  flip: True  # flip the x-axis in Singapore (left hand drive)
  fgbg_label: False  # use foreground background labels to train the model

##Training
model:
  resume_ckpt:
  loss_type: "l1"  # "l1", "l2", "absrel" for pre-training only
  loss_weight: {depth: 1.0, occlusion: 0.0}  # loss weight for "depth" and "occlusion"
  optimizer: "adam"
  lr_start: 0.0001  # 4dmos: 0.0001, 4docc_org: 0.0005
  lr_epoch: 1       # 4dmos: 1       4docc_org: 5
  lr_decay: 0.9     # 4dmos: 0.99    4docc_org: 0.1
  weight_decay:  # not used
  num_epoch: 50000
  batch_size: 1
  acc_batches: 1 # accumulate gradients over k batches before stepping into the optimizer
  num_workers: 8
  num_devices: 1 # could be integer of how many cuda devices to use, or a list that specify which devices to use [0, 1, 2, 3]
  # AUGMENTATION: True

# Dataset Config
dataset:
  nuscenes:
    root: "/home/user/Datasets/nuScenes" # "/root/autodl-tmp/datasets/nuscenes" "/home/user/Datasets/nuScenes"
    version: "v1.0-trainval"
  kitti:
    root: "/home/user/Datasets/KITTI"
    config: "configs/semantic-kitti.yaml"
  argo:
    root: "/home/user/Datasets/ArgoVerse2/LiDAR/"
