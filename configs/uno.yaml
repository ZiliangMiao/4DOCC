# Pretraining params
uno:
  # dataset related
  dataset_name: "nuscenes" # "sekitti", "KITTITRA", "KITTITRA_M", "APOLLO", "nuscenes", "WAYMO_M", "AVIA"
  downsample_level: "sequence" # "sequence", "sample", "none"
  downsample_pct: 100 # use 10% of training dataset to train the model
  shuffle: True # shuffle dataset, must for training set
  augmentation: True

  # data processing related
  n_input: 6
  n_skip: 0
  scene_bbox: [-70.0, -70.0, -5.0, 70.0, 70.0, 5.0] # valid point cloud range
  quant_size: 0.1 # used for discretization in x,y,z when creating a sparse tensor
  time_interval: 0.5 # sample data time interval, nusc: 0.05, kitti: 0.1; sample time interval: nusc: 0.5
  pos_dim: 4 # x, y, z, t
  feat_dim: 128 # feature dimension of each point [128]
  hidden_size: 16 # [16]
  featmap_size: 0.4 # feature map resolution
  transform: True # if true, the points are pose-aligned before feeding to the model
  ego_mask: True
  outside_scene_mask: True
  outside_scene_mask_z: True
  outside_scene_mask_ub: False # upper bound, if true, x <= x_max, else x < x_max
  occ_thrd: 0.1
  n_sd_per_sample: 1
  num_rays: 5000 # number of down-sampled rays per sample [5000]
  num_ray_cls_samples: 10 # number of uno samples per ray per class [10]

  # training related
  num_epoch: 100
  batch_size: 16
  acc_batches: 1 # accumulate gradients over k batches before stepping into the optimizer
  num_cls: 2 # 0-free, 1-occ
  lr_start: 0.00008  # refer to UnO
  lr_max: 0.0008  # refer to UnO
  lr_min: 0  # refer to UnO
  weight_decay: 0.0001  # refer to UnO

  # device related
  num_workers: 16
  num_devices: 1 # int: number of cuda devices to use; list: specify which devices to use [0, 1, 2, 3]


# Background samples test
uno_test:
  model_dir: '/home/user/Projects/4DOCC/logs/ours/bg_pretrain/100%nuscenes/vs-0.1_t-3.0_bs-4/version_0'
  test_epoch: 54
  test_dataset: 'nuscenes'
  num_devices: 1
